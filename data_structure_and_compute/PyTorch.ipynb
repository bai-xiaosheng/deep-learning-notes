{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义\n",
    "\n",
    "`PyTorch` 是一种深度学习**框架**，包含 `Tensor` 数据结构、自动求导、神经网络(nn)、优化器(optim)、数据加载(utils.data)、设备(GPU加速)\n",
    "\n",
    "\n",
    "## PyTorch 特性\n",
    "* 动态计算图\n",
    "* 自动微分\n",
    "* 张量计算\n",
    "* 丰富的API\n",
    "\n",
    "## Ternsor\n",
    "`Tensor` 是一个多维数组，跟 `ndarray` 类似，但支持GPU加速、自动微分和动态计算图计算。\n",
    "\n",
    "组成部分：\n",
    "* 数据：以一维数组的形式存储数据，通过 `shape` 和 `stride` 属性映射到多维视图中。\n",
    "* 形状：`shape` 表示张量的维度，例如（3，224，244）表示三通道，224x224大小的张量，可以通过`torch.shape` 或者 `torch.size()` 查看\n",
    "* `Dtype`：数据类型，例如：torch.float32,torch.int64，可以通过 `torch.dtype` 查看，在创建时可以指定参数类型\n",
    "* 设备：通过 `device` 参数设定\n",
    "* 梯度跟踪：布尔值，表示是否追踪该 Tensor 的梯度，通过`tensor.requires_grad` 查看或者设置\n",
    "\n",
    "\n",
    "## PyTorch、Torch、Tensor的关系\n",
    "PyTorch是一个框架，基于 `Torch` 库实现，也可以认为是一个大的库。\n",
    "\n",
    "`Tensor` 是一个具体的数据结构\n",
    "\n",
    "## Pytorch 和 Numpy 的关系\n",
    "\n",
    "Numpy是python中一个科学计算基本库，提供了一个多维数组对象 `ndarray` 主要用于数值计算，不支持自动求导，仅支持CPU计算\n",
    "\n",
    "Tensor 和 Numpy 可以相互转换，但需要注意设备位置（需要在CPU上），转换方法：\n",
    "\n",
    "1. .numpy():将 tensor 转换为 numpy.\n",
    "2. torch.from_numpy(): 将 numpy 转换为 tensor。注意这种转换方式是指两者共享相同的内存，一个改变另一个也会改变\n",
    "3. torch.tensor(): 将 numpy 转换为 tensor，返回的Tensor和原来的numpy数据不再共享内存。所以计算速度慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor 常用计算\n",
    "1. 创建操作\n",
    "   1. 从 Python 列表创建\n",
    "   2. 创建全零或者全1张量\n",
    "   3. 随机初始化\n",
    "2. 数学运算\n",
    "   1. 逐元素运算\n",
    "   2. 矩阵乘法\n",
    "   3. 聚合操作\n",
    "3. 形状操作\n",
    "   1. 改变形状\n",
    "   2. 转置\n",
    "4. 自动微分\n",
    "   1. 启动梯度\n",
    "   2. 计算梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建tensor\n",
    "\n",
    "torch.Tensor()是指创建一个浮点数的 tensor， 等同于 torch.FloatTensor()，类似的还有 torch.IntTensor, torch.LongTensor(), torch.DoubleTensor().不推荐使用\n",
    "\n",
    "torch.tensor()需要在里面指定 tensor 类型。推荐使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor torch.FloatTensor torch.FloatTensor\n",
      "tensor([0, 1, 2, 3]) tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([0, 1])\n",
    "# a = torch.Tensor([[0,1],[2,0]], dtype=torch.int64)  错误，torch1.8版本以后，Tensor不支持指定类型\n",
    "b = torch.FloatTensor([0, 1])\n",
    "c = torch.tensor([[0, 1], [2, 0]], dtype=torch.float32) # 推荐\n",
    "\n",
    "print(a.type(), b.type(), c.type())\n",
    "\n",
    "d = torch.arange(0, 4)\n",
    "e = torch.linspace(0, 10, steps=5)  # steps 表示分割次数\n",
    "print(d,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 生成特殊张量\n",
    "zeros = torch.zeros(2,3)\n",
    "ones = torch.ones(2, 3)\n",
    "print(zeros)\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6639, 0.6776, 0.4407],\n",
      "        [0.6362, 0.5896, 0.1015]])\n",
      "tensor([[0.8827, 0.1971, 0.7692],\n",
      "        [0.0270, 0.4255, 0.3934]])\n"
     ]
    }
   ],
   "source": [
    "# 随机初始化\n",
    "rand = torch.rand(2, 3)  # 标准均匀分布随机值\n",
    "print(rand)\n",
    "randn = torch.rand(2, 3)   # 标准正态分布随机值\n",
    "print(randn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数学运算\n",
    "* 逐元素运算\n",
    "* 矩阵乘法\n",
    "* 聚合运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逐元素运算\n",
    "a + b  # 加法（等价于 torch.add(a, b)）\n",
    "a * b  # 逐元素乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 矩阵乘法\n",
    "matmul = torch.matmul(a, b)\n",
    "# 或者使用 @\n",
    "matmul = a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor([[0., 1.],\n",
      "        [2., 0.]])\n",
      "tensor([1.0000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "# 聚合运算\n",
    "sum = torch.sum(a)  # 默认所有数据求和，可以设置维度\n",
    "print(sum)\n",
    "print(c)\n",
    "mean = torch.mean(c,dim=0)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变形状\n",
    "1. 改变形状\n",
    "   1. torch.view 不改变张量的数据，只是改变 shape 和 stride，但要求张量必须是连续的，如果不连续，需要调用 `torch.contiguous` 方法使张量连续,在内存连续的情况下，view性能更高效\n",
    "   2. torch.reshape 在张量内存连续时，与view相同，不复制数据，如果，张量不连续，会复制数据。优点在于能够自动处理不连续的张量\n",
    "2. 转置\n",
    "   1. 经过转置后，张量在内存中不连续\n",
    "   2. .T 适用于二维矩阵\n",
    "   3. torch.transpose() 交换张量两个指定的维度，与原张量共享数据\n",
    "   4. torch.permute() 同时调整多个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.]])\n",
      "tensor([[2., 1.],\n",
      "        [2., 0.]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 改变形状\n",
    "reshaped = c.view(4,1)\n",
    "print(reshaped)\n",
    "reshaped[0] = 2\n",
    "print(c)\n",
    "print(reshaped.is_contiguous())  # True 表示连续"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]]) (3, 1)\n",
      "tensor([[ 0,  3,  6,  9],\n",
      "        [ 1,  4,  7, 10],\n",
      "        [ 2,  5,  8, 11]]) False (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# 转置\n",
    "c = torch.arange(0,12).view(4,3)\n",
    "transposed = c.T\n",
    "print(c,c.stride())\n",
    "transpesed = torch.transpose(c, 0, 1)\n",
    "print(transpesed, transpesed.is_contiguous(), transpesed.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动微分相关\n",
    "1. 启动梯度跟踪\n",
    "2. 计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动梯度跟踪\n",
    "x = torch.tensor([1.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# 计算梯度\n",
    "y = x ** 2\n",
    "num = y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他常用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 0, 1, 0],\n",
      "        [0, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "# one-hot 编码\n",
    "a = torch.arange(4)\n",
    "a = F.one_hot(a, 4)\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learn_note",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
