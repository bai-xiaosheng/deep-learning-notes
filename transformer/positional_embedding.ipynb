{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考链接\n",
    "[Sinusoidal位置编码](https://spaces.ac.cn/archives/8231 \"苏剑林\")\n",
    "\n",
    "[位置编码的理解](https://spaces.ac.cn/archives/10347 \"苏剑林\")\n",
    "\n",
    "[让研究人员绞尽脑汁的Transformer位置编码](https://spaces.ac.cn/archives/8130 \"苏剑林\")\n",
    "\n",
    "[RoPE位置编码](https://spaces.ac.cn/archives/8265 \"苏剑林，该方法提出者\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 位置编码的作用\n",
    "### 1. **破环Attention的置换不变性**\n",
    "置换不变性是指对于双向attetion而言，$f(...,x_m,...,x_n) = f(...,x_n,...,x_m)$,及个体在整体中的不同位置具有相同的效果，显然不符合语言常识。\n",
    "\n",
    "### 2. 添加先验知识\n",
    "位置信息可以作为attention的一种先验知识。\n",
    "sinusoidal位置编码使用三角函数生成的绝对位置编码，并且相邻的两个向量相似度更高，隐含了相近的token应该具有相近的Embedding的先验。Bert也是绝对位置编码\n",
    "相对位置编码（主流）和诸如RNN、CNN等模型也自然的包含先验知识，越近的token越重要\n",
    "虽然不需要位置编码（NoPE+Cross Attention）也取得了比较的好的结果，crossattention是指单边注意力机制，只能看到自己和之前的信息，这种注意力本身就不具备置换不变性。这种单向注意力机制其方差也包含了位置信息。但实际上只是说这种方法能够取得跟加位置编码相似的结果，无法证明其优越性。\n",
    "\n",
    "在苏神的文章中提出：越少的先验信息，代表人为的偏见和误区更少，从而天花板更高。这个观点很有趣"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 位置编码的目标\n",
    "1. 位置信息：绝对位置信息和相对位置信息\n",
    "2. 远程衰减：距离越远，相关性应该适当衰减"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 位置编码方式\n",
    "* 绝对位置编码：sinusoidal位置编码，transformer论文中提到的那种编码方式\n",
    "* 相对位置编码：RoPE位置编码，主流的编码方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input shape: torch.Size([2, 4, 10, 64])\n",
      "Input with position encoding shape: torch.Size([2, 4, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "class SinusoidalPositional(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        # 计算每个头的维度\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        head_dim = d_model // num_heads\n",
    "        pe = torch.zeros((max_len, head_dim))\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(dim=1)\n",
    "        dim = torch.exp(- torch.arange(0, head_dim, 2) * torch.log(torch.tensor(10000.0)) / head_dim)\n",
    "        pe[:, 0::2] = torch.sin(pos * dim)\n",
    "        pe[:, 1::2] = torch.cos(pos * dim)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\",pe)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"sinusoidal位置编码实现\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): batch_size, num_heads, seq_len, head_dim\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: batch_size, num_heads, seq_len, head_dim\n",
    "        \"\"\"\n",
    "        batch_size, num_heads, seq_len, _ = x.size()\n",
    "        pe = self.pe[:,:seq_len,:].unsqueeze(1).expand(-1, num_heads, -1, -1)\n",
    "        return x + pe\n",
    "\n",
    "# 示例使用多头注意力输入\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义参数\n",
    "    batch_size = 2\n",
    "    num_heads = 4\n",
    "    seq_len = 10\n",
    "    head_dim = 64\n",
    "    d_model = num_heads * head_dim\n",
    "\n",
    "    # 创建多头注意力输入张量\n",
    "    x = torch.randn(batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "    # 创建正弦位置编码模块\n",
    "    pos_encoder = SinusoidalPositional(d_model, num_heads)\n",
    "\n",
    "    # 应用位置编码\n",
    "    x_with_pos = pos_encoder(x)\n",
    "\n",
    "    print(\"Original input shape:\", x.shape)\n",
    "    print(\"Input with position encoding shape:\", x_with_pos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoPE\n",
    "是一种用绝对位置编码实现相对位置编码的方式。能够适用于线性attention。注意下面是工程实现版本，跟原始论文中的公式存在一点出入，但不影响结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case1 Output: tensor([[[[1., 2., 3., 4.]]]])\n",
      "Case2 Output shape: torch.Size([2, 8, 256, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"优化维度注释和负数处理\"\"\"\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, freqs):\n",
    "    \"\"\"支持多头注意力的版本\"\"\"\n",
    "    # freqs 维度: [1, 1, seq_len, dim]\n",
    "    # q/k 维度:   [batch, heads, seq_len, dim]\n",
    "    q_rot = (q * freqs.cos()) + (rotate_half(q) * freqs.sin())\n",
    "    k_rot = (k * freqs.cos()) + (rotate_half(k) * freqs.sin())\n",
    "    return q_rot, k_rot\n",
    "\n",
    "class RotaryPositionEmbedding(nn.Module):\n",
    "    def __init__(self, dim: int, base: int=10000, max_seq_len: int = 2048):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        # 更准确的变量命名\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "    def forward(self, q, k, seq_len=None):\n",
    "        \"\"\"支持多头注意力的维度版本\n",
    "        Args:\n",
    "            q: [batch, heads, seq_len, dim]\n",
    "            k: [batch, heads, seq_len, dim]\n",
    "        \"\"\"\n",
    "        device, dtype = q.device, q.dtype\n",
    "        seq_len = seq_len if seq_len else q.size(-2)\n",
    "        \n",
    "        # 动态生成位置编码\n",
    "        t = torch.arange(seq_len, device=device, dtype=dtype)\n",
    "        freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        \n",
    "        # 维度对齐调整 [batch, heads, seq, dim]\n",
    "        return apply_rotary_pos_emb(q, k, emb.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "        \n",
    "\n",
    "# 多维度测试案例\n",
    "def test_rope():\n",
    "    dim = 4\n",
    "    # 案例1：基础测试\n",
    "    x = torch.tensor([[[[1.0, 2.0, 3.0, 4.0]]]])  # [1,1,1,4]\n",
    "    rope = RotaryPositionEmbedding(dim)\n",
    "    q_rot, k_rot = rope(x, x)\n",
    "    print(\"Case1 Output:\", q_rot)\n",
    "\n",
    "    # 案例2：多头测试\n",
    "    x_multihead = torch.randn(2, 8, 256, dim)  # [batch=2, heads=8, seq=256, dim=4]\n",
    "    q_rot, k_rot = rope(x_multihead, x_multihead)\n",
    "    print(\"Case2 Output shape:\", q_rot.shape)\n",
    "\n",
    "\n",
    "test_rope()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
